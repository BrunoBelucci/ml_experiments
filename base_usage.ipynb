{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "589b2f1c",
   "metadata": {},
   "source": [
    "# ML Experiments usage example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae232204",
   "metadata": {},
   "source": [
    "The main goal of ml_experiments is to provide a simple way to track and manage machine learning experiments. It can help by automatically logging parameters through mlflow and by providing a simple interface for different machine learning tasks. The main usage consists in creating a new class inheriting from either BaseExperiment or HPOExperiment, depending on whether we want to perform hyperparameter optimization or not. Let's illustrate a simple example on how to use ml_experiments to train a simple classification model on the iris dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d306a",
   "metadata": {},
   "source": [
    "## Creating an experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5044c2eb",
   "metadata": {},
   "source": [
    "The minimal implementation of any experiment consists on the following methods:\n",
    "\n",
    "````python\n",
    "class ClassificationExperiment(BaseExperiment):\n",
    "    def _add_arguments_to_parser(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _unpack_parser(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _get_combinations_names(self) -> list[str]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _get_unique_params(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _get_extra_params(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _load_data(self, combination: dict, unique_params: dict, extra_params: dict, mlflow_run_id: str | None = None, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _load_model(self, combination: dict, unique_params: dict, extra_params: dict, mlflow_run_id: str | None = None, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _get_metrics(self, combination: dict, unique_params: dict, extra_params: dict, mlflow_run_id: str | None = None, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _fit_model(self, combination: dict, unique_params: dict, extra_params: dict, mlflow_run_id: str | None = None, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _evaluate_model(self, combination: dict, unique_params: dict, extra_params: dict, mlflow_run_id: str | None = None, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "````\n",
    "\n",
    "\n",
    "However several other methods are provided to be overridden if needed, they are:\n",
    "_on_train_start, _before_load_data, _after_load_data, _before_load_model, _after_load_model, _before_get_metrics, _after_get_metrics, _before_fit_model, _after_fit_model, _before_evaluate_model, _after_evaluate_model, _on_exception, _on_train_end\n",
    "\n",
    "Behind the scenes we call each method one after the other in the following order:\n",
    "````python\n",
    "\n",
    "self._on_train_start()\n",
    "self._before_load_data()\n",
    "self._load_data()\n",
    "self._after_load_data()\n",
    "self._before_load_model()\n",
    "self._load_model()\n",
    "self._after_load_model()\n",
    "self._before_get_metrics()\n",
    "self._get_metrics()\n",
    "self._after_get_metrics()\n",
    "self._before_fit_model()\n",
    "self._fit_model()\n",
    "self._after_fit_model()\n",
    "self._before_evaluate_model()\n",
    "self._evaluate_model()\n",
    "self._after_evaluate_model()\n",
    "self._on_train_end()\n",
    "````\n",
    "\n",
    "Each one of these methods takes the same parameters:\n",
    "````python\n",
    "def _method_name(self, combination: dict, unique_params: dict, extra_params: dict, mlflow_run_id: str | None = None, **kwargs):\n",
    "````\n",
    "where:\n",
    "- `combination` is a dictionary containing the parameters of the current combination being trained.\n",
    "- `unique_params` is a dictionary containing the unique parameters of the experiment.\n",
    "- `extra_params` is a dictionary containing the extra parameters of the experiment.\n",
    "- `mlflow_run_id` is the ID of the current MLflow run, if any.\n",
    "- `**kwargs` are the results of the previous methods that can be accessed if needed.\n",
    "\n",
    "Each method must return a dictionary, this dictionary can be accessed via the `**kwargs` parameter of any subsequent method. This allows to pass data between methods.\n",
    "The dictionary is accessed by the key `on_<method_name>_return`, so for example imagine we load the data in the `_load_data` method and return it as a dictionary containing the keys `X` and `y`, we can access it in the `_fit_model` method like this:\n",
    "\n",
    "```python\n",
    "def _load_data(self, combination: dict, unique_params: dict, extra_params: dict, mlflow_run_id: str | None = None, **kwargs):\n",
    "\t# Load data\n",
    "\tX = ...\n",
    "\ty = ...\n",
    "\treturn dict(X=X, y=y)\n",
    "\n",
    "def _fit_model(self, combination: dict, unique_params: dict, extra_params: dict, mlflow_run_id: str | None = None, **kwargs):\n",
    "\t# Access the loaded data\n",
    "\tload_data_return = kwargs['on_load_data_return']\n",
    "\tX = load_data_return['X']\n",
    "\ty = load_data_return['y']\n",
    "````\n",
    "\n",
    "The combination is defined by the `_get_combinations_names` method, which returns a list of strings with the attributes names of the experiment that should be considered as combinations. We will iterate trough the product of these combinations, executing the whole training process for each combination. The combinations parameters are typically the datasets or models configurations (names, seeds, etc). For example, imagine that we are training a `GradientBoostingClassifier` on the iris dataset and we want to split it in different traing and test sets by using different random seeds, besides, we also want to be able to train several models with different n_estimators. In this case, we would define the combinations as follows:\n",
    "\n",
    "```python\n",
    "class ClassificationExperiment(BaseExperiment):\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\t*args,\n",
    "\t\tseed: int | list[int] = 42,\n",
    "\t\tn_estimators: int | list[int] = 100,\n",
    "\t\t**kwargs\n",
    "\t):\n",
    "\t\tsuper().__init__(*args, **kwargs)\n",
    "\t\tself.seed = seed\n",
    "\t\tself.n_estimators = n_estimators\n",
    "\n",
    "def _get_combinations_names(self) -> list[str]:\n",
    "\treturn ['seed', 'n_estimators']\n",
    "```\n",
    "\n",
    "This would allow us to train the model with all the combinations of the `seed` and `n_estimators` parameters, for example, if we pass `seed=[42, 43]` and `n_estimators=[100, 200]`, we would train the model with the following combinations:\n",
    "\n",
    "```\n",
    "- seed=42, n_estimators=100\n",
    "- seed=42, n_estimators=200\n",
    "- seed=43, n_estimators=100\n",
    "- seed=43, n_estimators=200\n",
    "```\n",
    "\n",
    "In the same manner, imagine that we would also like to control the learning rate of the model, but without considering it as a combination, we would define it as a unique parameter:\n",
    "\n",
    "```python\n",
    "class ClassificationExperiment(BaseExperiment):\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\t*args,\n",
    "\t\tseed: int | list[int] = 42,\n",
    "\t\tn_estimators: int | list[int] = 100,\n",
    "\t\tlearning_rate: float = 0.1,\n",
    "\t\t**kwargs\n",
    "\t):\n",
    "\t\tsuper().__init__(*args, **kwargs)\n",
    "\t\tself.seed = seed\n",
    "\t\tself.n_estimators = n_estimators\n",
    "\t\tself.learning_rate = learning_rate\n",
    "\n",
    "\tdef _get_unique_params(self):\n",
    "\t\tunique_params = super()._get_unique_params()\n",
    "\t\tunique_params.update({\n",
    "\t\t\t'learning_rate': self.learning_rate,\n",
    "\t\t})\n",
    "\t\treturn unique_params\n",
    "```\n",
    "\n",
    "The unique parameters are not considered as combinations, so they will be the same for all the combinations. However, if we change the `learning_rate` parameter this would certainly imply in a different model with different results. Note that we use the super() method to consider the unique_params of the parent class. If the parameter would not influence the results, we could define it as an extra parameter instead. For example, imagine that we want to control the verbosity of the model, but it does not influence the results, we would define it as an extra parameter:\n",
    "\n",
    "```python\n",
    "class ClassificationExperiment(BaseExperiment):\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\t*args,\n",
    "\t\tseed: int | list[int] = 42,\n",
    "\t\tn_estimators: int | list[int] = 100,\n",
    "\t\tlearning_rate: float = 0.1,\n",
    "\t\tverbose: bool = False,\n",
    "\t\t**kwargs\n",
    "\t):\n",
    "\t\tsuper().__init__(*args, **kwargs)\n",
    "\t\tself.seed = seed\n",
    "\t\tself.n_estimators = n_estimators\n",
    "\t\tself.learning_rate = learning_rate\n",
    "\t\tself.verbose = verbose\n",
    "\n",
    "\tdef _get_extra_params(self):\n",
    "\t\textra_params = super()._get_extra_params()\n",
    "\t\textra_params.update({\n",
    "\t\t\t'verbose': self.verbose,\n",
    "\t\t})\n",
    "\t\treturn extra_params\n",
    "```\n",
    "\n",
    "The difference between `unique_params` and `extra_params` is that we log both combinations and unique parameters in MLflow, while extra parameters are not logged. \n",
    "\n",
    "Finally, for convenience, any experiment can be directly run from the command line, for this we need to implement the `_add_arguments_to_parser` and `_unpack_parser` methods. The first one is used to add the arguments to the argument parser (from the `argparse` module), while the second one is used to unpack the arguments from the parser. For example, we can add the `seed`, `n_estimators`, `learning_rate` and `verbose` parameters as follows:\n",
    "\n",
    "```python\n",
    "def _add_arguments_to_parser(self):\n",
    "\tself.parser.add_argument('--seed', type=int, nargs='+', default=[42], help='Random seed for the experiment')\n",
    "\tself.parser.add_argument('--n_estimators', type=int, nargs='+', default=[100], help='Number of estimators for the model')\n",
    "\tself.parser.add_argument('--learning_rate', type=float, default=0.1, help='Learning rate for the model')\n",
    "\tself.parser.add_argument('--verbose', action='store_true', help='Whether to print verbose output')\n",
    "\n",
    "def _unpack_parser(self):\n",
    "\targs = self.parser.parse_args()\n",
    "\tself.seed = args.seed\n",
    "\tself.n_estimators = args.n_estimators\n",
    "\tself.learning_rate = args.learning_rate\n",
    "\tself.verbose = args.verbose\n",
    "\treturn args\n",
    "```\n",
    "\n",
    "This allows us to run the experiment from the command line, for example:\n",
    "\n",
    "```python my_experiment.py --seed 42 43 --n_estimators 100 200 --learning_rate 0.1 --verbose```\n",
    "\n",
    "The BaseExperiment class already provide several parameters that can be passed either through the command line or as arguments to the constructor, these parameters are:\n",
    "\n",
    "- `experiment_name`: The name of the experiment, used to create a new MLflow experiment.\n",
    "- `mlflow_tracking_uri`: The URI of the MLflow tracking server, if not set\n",
    "- `log_dir`: The directory where the logs will be saved.\n",
    "- `log_file_name`: The name of the log file.\n",
    "- `work_root_dir`: The root directory that each training process can use to store intermediate results (fast access) that can be cleared after the training is finished.\n",
    "- `save_root_dir`: The root directory where the final results will be saved.\n",
    "- `clean_work_dir`: Whether to clean the `work_dir` (and `work_root_dir` if empty) after the training is finished.\n",
    "- `raise_on_error`: Whether to raise an exception if an error occurs during the training process or to try to continue with the next combination.\n",
    "- `parser`: An ArgumentParser instace if it is created outside the experiment class, otherwise it will be created automatically.\n",
    "- `timeout_fit`: The timeout in seconds for the fitting process, if not set it will wait indefinitely, otherwise it will raise an exception if the fitting process takes longer than this time.\n",
    "- `timeout_combination`: The timeout in seconds for each combination, if not set it will wait indefinitely, otherwise it will raise an exception if the combination takes longer than this time.\n",
    "- `verbose`: Whether to print verbose output, this is used to control the verbosity of the logs.\n",
    "- `profile_time`: Whether to profile the time taken by each method, this is used to measure the time taken by each method and log it in MLflow, we can choose to profile the time of any method by using the decorator @profile_time(enable_based_on_attribute='profile_time') on the method definition.\n",
    "- `profile_memory`: Whether to profile the memory usage of each method, this is used to measure the memory usage of each method and log it in MLflow, we can choose to profile the memory of any method by using the decorator @profile_memory(enable_based_on_attribute='profile_memory') on the method definition. \n",
    "\n",
    "Note that by default, if we not set any of these parameters, the feature will be disabled, so for example, if we do not pass a `mlflow_tracking_uri`, the experiment will not log anything to MLflow, and if we do not pass a `log_dir`, the logs will not be saved to any file.\n",
    "\n",
    "Also note that we pass the root directory for the work directory and the save directory, so that each training process can use its own work directory, this is useful for parallel execution of the training process. The current `work_dir` and `save_dir` can also be accessed through the kwargs parameter of each method, using the keys \n",
    "`work_dir` and `save_dir`, respectively.\n",
    "\n",
    "Besides, some parameters from the `dask` library are also defined to allow parallel execution of the training process:\n",
    "\n",
    "- `dask_cluster_type`: The type of Dask cluster to use, can be 'local' or 'slurm'.\n",
    "- `n_workers`: The number of workers to use in the Dask cluster.\n",
    "- `n_processes_per_worker`: The number of processes to use per worker in the Dask cluster.\n",
    "- `n_cores_per_worker`: The number of cores to use per worker in the Dask cluster.\n",
    "- `n_threads_per_worker`: The number of threads to use per worker in the Dask cluster.\n",
    "- `n_processes_per_task`: The number of processes used for each task (training process).\n",
    "- `n_processes_per_task`: The number of processes used for each task (training process).\n",
    "- `n_cores_per_task`: The number of cores used for each task (training process).\n",
    "- `n_threads_per_task`: The number of threads used for each task (training process).\n",
    "- `dask_memory`: The memory limit for each worker in the Dask cluster.\n",
    "- `dask_job_extra_directives`: Extra directives to be passed to the Dask job when using a Slurm cluster.\n",
    "- `dask_address`: The address of a Dask cluster if it is already running.\n",
    "- `n_gpus_per_worker`: The number of GPUs to use per worker, it can be a fraction of a GPU, for example 0.5 means half a GPU.\n",
    "- `n_gpus_per_task`: The number of GPUs to use per task, it can be a fraction of a GPU, for example 0.5 means half a GPU.\n",
    "\n",
    "Let's now illustrate the full implementation of the `ClassificationExperiment` class, which will train a `GradientBoostingClassifier` on the iris dataset:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05dddfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_experiments import BaseExperiment\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class ClassificationExperiment(BaseExperiment):\n",
    "    def __init__(\n",
    "            self,\n",
    "            *args,\n",
    "            seed: int | list[int] = 42,\n",
    "            n_estimators: int | list[int] = 100,\n",
    "            learning_rate: float = 0.1,\n",
    "            model_verbose: int = 1,\n",
    "            **kwargs\n",
    "        ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.seed = seed\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model_verbose = model_verbose\n",
    "\n",
    "    def _add_arguments_to_parser(self):\n",
    "        self.parser.add_argument(\t\t\t\n",
    "            \"--seed\",\n",
    "            type=int,\n",
    "            nargs=\"+\",\n",
    "            default=self.seed,\n",
    "            help=\"Random seed for reproducibility.\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--n_estimators\",\n",
    "            type=int,\n",
    "            nargs=\"+\",\n",
    "            default=self.n_estimators,\n",
    "            help=\"Number of estimators for the model.\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--learning_rate\",\n",
    "            type=float,\n",
    "            default=self.learning_rate,\n",
    "            help=\"Learning rate for the model.\",\n",
    "        )\n",
    "        self.parser.add_argument(\n",
    "            \"--model_verbose\",\n",
    "            type=int,\n",
    "            default=self.model_verbose,\n",
    "            help=\"Verbosity level of the model training.\",\n",
    "            action='store_true'\n",
    "        )\n",
    "\n",
    "    def _unpack_parser(self):\n",
    "        args = super()._unpack_parser()\n",
    "        self.seed = args.seed\n",
    "        self.n_estimators = args.n_estimators\n",
    "        self.learning_rate = args.learning_rate\n",
    "        self.model_verbose = args.model_verbose\n",
    "\n",
    "    def _get_combinations_names(self) -> list[str]:\n",
    "        return ['seed', 'n_estimators'] \n",
    "\n",
    "    def _get_unique_params(self):\n",
    "        unique_params = super()._get_unique_params()\n",
    "        unique_params.update({\n",
    "            'learning_rate': self.learning_rate,\n",
    "        })\n",
    "        return unique_params\n",
    "\n",
    "    def _get_extra_params(self):\n",
    "        extra_params = super()._get_extra_params()\n",
    "        extra_params.update(\n",
    "            {\n",
    "                \"model_verbose\": self.model_verbose,\n",
    "            }\n",
    "        )\n",
    "        return extra_params\n",
    "\n",
    "    def _load_data(\n",
    "        self, combination: dict, unique_params: dict, extra_params: dict, mlflow_run_id: str | None = None, **kwargs\n",
    "    ):\n",
    "        seed = combination[\"seed\"]\n",
    "        iris = load_iris()\n",
    "        X, y = iris.data, iris.target\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=seed\n",
    "        )\n",
    "        return dict(\n",
    "            X_train=X_train,\n",
    "            X_test=X_test,\n",
    "            y_train=y_train,\n",
    "            y_test=y_test,\n",
    "        )\n",
    "\n",
    "    def _load_model(\n",
    "        self, combination: dict, unique_params: dict, extra_params: dict, mlflow_run_id: str | None = None, **kwargs\n",
    "    ):\n",
    "        n_estimators = combination[\"n_estimators\"]\n",
    "        learning_rate = unique_params[\"learning_rate\"]\n",
    "        verbose = extra_params[\"model_verbose\"]\n",
    "        model = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            learning_rate=learning_rate,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        return dict(model=model)\n",
    "\n",
    "    def _get_metrics(\n",
    "        self, combination: dict, unique_params: dict, extra_params: dict, mlflow_run_id: str | None = None, **kwargs\n",
    "    ):\n",
    "        return dict(accuracy=accuracy_score)\n",
    "\n",
    "    def _fit_model(\n",
    "        self, combination: dict, unique_params: dict, extra_params: dict, mlflow_run_id: str | None = None, **kwargs\n",
    "    ):\n",
    "        model = kwargs[\"load_model_return\"][\"model\"]\n",
    "        X_train = kwargs[\"load_data_return\"][\"X_train\"]\n",
    "        y_train = kwargs[\"load_data_return\"][\"y_train\"]\n",
    "        model.fit(X_train, y_train)\n",
    "        return dict()\n",
    "\n",
    "    def _evaluate_model(\n",
    "        self, combination: dict, unique_params: dict, extra_params: dict, mlflow_run_id: str | None = None, **kwargs\n",
    "    ):\n",
    "        accuracy_fn = kwargs[\"get_metrics_return\"][\"accuracy\"]\n",
    "        model = kwargs[\"load_model_return\"][\"model\"]\n",
    "        X_test = kwargs[\"load_data_return\"][\"X_test\"]\n",
    "        y_test = kwargs[\"load_data_return\"][\"y_test\"]\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_fn(y_test, y_pred)\n",
    "        return dict(accuracy=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3335badf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-26 16:03:29\n",
      "Starting experiment...\n",
      "combination_names: ['seed', 'n_estimators']\n",
      "combinations: [(42, 100)]\n",
      "unique_params: {'timeout_fit': None, 'timeout_combination': None, 'learning_rate': 0.1}\n",
      "extra_params: {'model_verbose': 0}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0277793399e45498573de6b03ea5311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Combinations completed:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-26 16:03:29\n",
      "Running...\n",
      "seed: 42\n",
      "n_estimators: 100\n",
      "timeout_fit: None\n",
      "timeout_combination: None\n",
      "learning_rate: 0.1\n",
      "\n",
      "2025-06-26 16:03:29\n",
      "Finished!\n",
      "total_elapsed_time: 0.2398698080005488\n",
      "seed: 42\n",
      "n_estimators: 100\n",
      "timeout_fit: None\n",
      "timeout_combination: None\n",
      "learning_rate: 0.1\n",
      "\n",
      "2025-06-26 16:03:29\n",
      "Combinations completed:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "succesfully_completed: 1\n",
      "failed: 0\n",
      "none: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can now run the experiment with the `run` method\n",
    "\n",
    "experiment = ClassificationExperiment(\n",
    "\tseed=42,\n",
    "\tn_estimators=100,\n",
    "\tlearning_rate=0.1,\n",
    "\tmodel_verbose=0,\n",
    ")\n",
    "results = experiment.run(return_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3750eec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work_dir\n",
      "save_dir\n",
      "load_data_return\n",
      "  X_train\n",
      "  X_test\n",
      "  y_train\n",
      "  y_test\n",
      "load_model_return\n",
      "  model\n",
      "get_metrics_return\n",
      "  accuracy\n",
      "max_memory_used_before_fit\n",
      "max_memory_used_after_fit\n",
      "evaluate_model_return\n",
      "  accuracy\n",
      "total_elapsed_time\n",
      "combination\n",
      "  seed\n",
      "  n_estimators\n",
      "unique_params\n",
      "  timeout_fit\n",
      "  timeout_combination\n",
      "  learning_rate\n",
      "extra_params\n",
      "  model_verbose\n",
      "mlflow_run_id\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# The results are returned as a list of dicts, one for each combination, with the results returned by each method, we can check them with the following convenience method:\n",
    "from ml_experiments.utils import print_keys\n",
    "                \n",
    "print_keys(results[0])  # Print keys of the first result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "657130ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# The accuracy can be for example accessed like:\n",
    "\n",
    "accuracy = results[0][\"evaluate_model_return\"][\"accuracy\"]\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7d32074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-26 16:05:21\n",
      "Starting experiment...\n",
      "combination_names: ['seed', 'n_estimators']\n",
      "combinations: [(42, 100), (42, 200), (43, 100), (43, 200)]\n",
      "unique_params: {'timeout_fit': None, 'timeout_combination': None, 'learning_rate': 0.1}\n",
      "extra_params: {'model_verbose': 0}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5835e533bbc64f94b661b14a7065b489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Combinations completed:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-26 16:05:21\n",
      "Running...\n",
      "seed: 42\n",
      "n_estimators: 100\n",
      "timeout_fit: None\n",
      "timeout_combination: None\n",
      "learning_rate: 0.1\n",
      "\n",
      "2025-06-26 16:05:21\n",
      "Finished!\n",
      "total_elapsed_time: 0.2758839699999953\n",
      "seed: 42\n",
      "n_estimators: 100\n",
      "timeout_fit: None\n",
      "timeout_combination: None\n",
      "learning_rate: 0.1\n",
      "\n",
      "2025-06-26 16:05:21\n",
      "Combinations completed:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "succesfully_completed: 1\n",
      "failed: 0\n",
      "none: 0\n",
      "\n",
      "2025-06-26 16:05:21\n",
      "Running...\n",
      "seed: 42\n",
      "n_estimators: 200\n",
      "timeout_fit: None\n",
      "timeout_combination: None\n",
      "learning_rate: 0.1\n",
      "\n",
      "2025-06-26 16:05:21\n",
      "Finished!\n",
      "total_elapsed_time: 0.42614832900017063\n",
      "seed: 42\n",
      "n_estimators: 200\n",
      "timeout_fit: None\n",
      "timeout_combination: None\n",
      "learning_rate: 0.1\n",
      "\n",
      "2025-06-26 16:05:21\n",
      "Combinations completed:  25%|██▌       | 1/4 [00:00<00:00,  3.44it/s]\n",
      "succesfully_completed: 2\n",
      "failed: 0\n",
      "none: 0\n",
      "\n",
      "2025-06-26 16:05:21\n",
      "Running...\n",
      "seed: 43\n",
      "n_estimators: 100\n",
      "timeout_fit: None\n",
      "timeout_combination: None\n",
      "learning_rate: 0.1\n",
      "\n",
      "2025-06-26 16:05:22\n",
      "Finished!\n",
      "total_elapsed_time: 0.21812369100007345\n",
      "seed: 43\n",
      "n_estimators: 100\n",
      "timeout_fit: None\n",
      "timeout_combination: None\n",
      "learning_rate: 0.1\n",
      "\n",
      "2025-06-26 16:05:22\n",
      "Combinations completed:  50%|█████     | 2/4 [00:00<00:00,  2.70it/s]\n",
      "succesfully_completed: 3\n",
      "failed: 0\n",
      "none: 0\n",
      "\n",
      "2025-06-26 16:05:22\n",
      "Running...\n",
      "seed: 43\n",
      "n_estimators: 200\n",
      "timeout_fit: None\n",
      "timeout_combination: None\n",
      "learning_rate: 0.1\n",
      "\n",
      "2025-06-26 16:05:22\n",
      "Finished!\n",
      "total_elapsed_time: 0.432727813999918\n",
      "seed: 43\n",
      "n_estimators: 200\n",
      "timeout_fit: None\n",
      "timeout_combination: None\n",
      "learning_rate: 0.1\n",
      "\n",
      "2025-06-26 16:05:22\n",
      "Combinations completed:  75%|███████▌  | 3/4 [00:01<00:00,  3.31it/s]\n",
      "succesfully_completed: 4\n",
      "failed: 0\n",
      "none: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If we want to run several combinations, we can directly pass them as lists to the constructor:\n",
    "experiment = ClassificationExperiment(\n",
    "\tseed=[42, 43],\n",
    "\tn_estimators=[100, 200],\n",
    "\tlearning_rate=0.1,\n",
    "\tmodel_verbose=0,\n",
    ")\n",
    "results = experiment.run(return_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bef25f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have run 4 combinations.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We have run {len(results)} combinations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58df40d",
   "metadata": {},
   "source": [
    "Finally, if we want to automatically log the parameters and results to MLflow, we can pass an `mlflow_tracking_uri`. This will tell the experiment to automatically log the combination, unique_params and the metrics (int or float values) returned by the `_evalute_model` method. It will also try to log every possible parameter of the object `model` if it finds it in the `load_model_retun` dict. Let's illustrate by logging to a sqlite database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "133d0f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-26 16:08:50\n",
      "Starting experiment...\n",
      "combination_names: ['seed', 'n_estimators']\n",
      "combinations: [(42, 100), (42, 200), (43, 100), (43, 200)]\n",
      "unique_params: {'timeout_fit': None, 'timeout_combination': None, 'learning_rate': 0.1}\n",
      "extra_params: {'model_verbose': 0}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3748ca2e9d4832ae53505d0370b093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Combinations completed:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/26 16:08:50 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/06/26 16:08:50 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\n",
      "INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "INFO  [alembic.runtime.migration] Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "INFO  [alembic.runtime.migration] Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
      "INFO  [alembic.runtime.migration] Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
      "INFO  [alembic.runtime.migration] Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0584bdc529eb -> 400f98739977, add logged model tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 400f98739977 -> 6953534de441, add step to inputs table\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "2025/06/26 16:08:51 WARNING mlflow.tracking.fluent: Cannot retrieve experiment by name base_experiment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-26 16:08:51\n",
      "Running...\n",
      "seed: 42\n",
      "n_estimators: 100\n",
      "timeout_fit: None\n",
      "timeout_combination: None\n",
      "learning_rate: 0.1\n",
      "\n",
      "2025-06-26 16:08:52\n",
      "Finished!\n",
      "total_elapsed_time: 0.22787985600007232\n",
      "seed: 42\n",
      "n_estimators: 100\n",
      "timeout_fit: None\n",
      "timeout_combination: None\n",
      "learning_rate: 0.1\n",
      "\n",
      "2025-06-26 16:08:52\n",
      "Combinations completed:   0%|          | 0/4 [00:01<?, ?it/s]\n",
      "succesfully_completed: 1\n",
      "failed: 0\n",
      "none: 0\n",
      "\n",
      "2025-06-26 16:08:52\n",
      "Running...\n",
      "seed: 42\n",
      "n_estimators: 200\n",
      "timeout_fit: None\n",
      "timeout_combination: None\n",
      "learning_rate: 0.1\n",
      "\n",
      "2025-06-26 16:08:52\n",
      "Finished!\n",
      "total_elapsed_time: 0.4372436289995676\n",
      "seed: 42\n",
      "n_estimators: 200\n",
      "timeout_fit: None\n",
      "timeout_combination: None\n",
      "learning_rate: 0.1\n",
      "\n",
      "2025-06-26 16:08:52\n",
      "Combinations completed:  25%|██▌       | 1/4 [00:02<00:05,  1.95s/it]\n",
      "succesfully_completed: 2\n",
      "failed: 0\n",
      "none: 0\n",
      "\n",
      "2025-06-26 16:08:52\n",
      "Running...\n",
      "seed: 43\n",
      "n_estimators: 100\n",
      "timeout_fit: None\n",
      "timeout_combination: None\n",
      "learning_rate: 0.1\n",
      "\n",
      "2025-06-26 16:08:52\n",
      "Finished!\n",
      "total_elapsed_time: 0.2284525750001194\n",
      "seed: 43\n",
      "n_estimators: 100\n",
      "timeout_fit: None\n",
      "timeout_combination: None\n",
      "learning_rate: 0.1\n",
      "\n",
      "2025-06-26 16:08:52\n",
      "Combinations completed:  50%|█████     | 2/4 [00:02<00:02,  1.14s/it]\n",
      "succesfully_completed: 3\n",
      "failed: 0\n",
      "none: 0\n",
      "\n",
      "2025-06-26 16:08:53\n",
      "Running...\n",
      "seed: 43\n",
      "n_estimators: 200\n",
      "timeout_fit: None\n",
      "timeout_combination: None\n",
      "learning_rate: 0.1\n",
      "\n",
      "2025-06-26 16:08:53\n",
      "Finished!\n",
      "total_elapsed_time: 0.40580426399992575\n",
      "seed: 43\n",
      "n_estimators: 200\n",
      "timeout_fit: None\n",
      "timeout_combination: None\n",
      "learning_rate: 0.1\n",
      "\n",
      "2025-06-26 16:08:53\n",
      "Combinations completed:  75%|███████▌  | 3/4 [00:03<00:00,  1.24it/s]\n",
      "succesfully_completed: 4\n",
      "failed: 0\n",
      "none: 0\n",
      "\n",
      "2025-06-26 16:08:53\n",
      "Experiment finished!\n",
      "total_elapsed_time: 3.4971002379998026\n",
      "total_combinations: 4\n",
      "sucessfully_completed: 4\n",
      "failed: 0\n",
      "none: 0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = ClassificationExperiment(\n",
    "    seed=[42, 43],\n",
    "    n_estimators=[100, 200],\n",
    "    learning_rate=0.1,\n",
    "    model_verbose=0,\n",
    "    mlflow_tracking_uri=\"sqlite:///example.db\"\n",
    ")\n",
    "experiment.run(return_results=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0dd49e",
   "metadata": {},
   "source": [
    "We can now check the results of the experiment by running the following mlflow command:\n",
    "```bash\n",
    "mlflow ui --backend-store-uri sqlite:///example.db\n",
    "```\n",
    "\n",
    "or we can programatically access the results by using the `mlflow` module. Please check the mlflow documentation for more information on how to use it (filter runs, check experiments, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb1480d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have found 4 runs.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///example.db\")\n",
    "\n",
    "runs = mlflow.search_runs()\n",
    "print(f\"We have found {len(runs)} runs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83cffe02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "run_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "experiment_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "artifact_uri",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start_time",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "end_time",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "metrics.max_memory_used_before_fit",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "metrics.max_memory_used_after_fit",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "metrics.total_elapsed_time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "metrics.accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "metrics.max_memory_used",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "params.validation_fraction",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.loss",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.min_weight_fraction_leaf",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.criterion",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.tol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.seed",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.min_samples_leaf",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.verbose",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.random_state",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.timeout_combination",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.subsample",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.max_leaf_nodes",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.max_depth",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.git_hash",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.timeout_fit",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.n_estimators",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.max_features",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.warm_start",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.work_dir",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.min_impurity_decrease",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.log_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.cuda_available",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.min_samples_split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.init",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.n_iter_no_change",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.ccp_alpha",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.learning_rate",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tags.mlflow.runName",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tags.raised_exception",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "f4246e82-a401-41a0-8cc6-c39e41553acc",
       "rows": [
        [
         "0",
         "8e8fc054b88b479ca408ce5f56e64860",
         "1",
         "FINISHED",
         "/home/belucci/code/ml_experiments/mlruns/1/8e8fc054b88b479ca408ce5f56e64860/artifacts",
         "2025-06-26 19:08:52.997000+00:00",
         "2025-06-26 19:08:53.465000+00:00",
         "330.304",
         "330.304",
         "0.40580426399992575",
         "0.9333333333333333",
         "330.304",
         "0.1",
         "log_loss",
         "0.0",
         "friedman_mse",
         "0.0001",
         "43",
         "1",
         "0",
         "None",
         "None",
         "1.0",
         "None",
         "3",
         "83e1c11371cc88d32a3f628247189140015a0b90",
         "None",
         "200",
         "None",
         "False",
         "/home/belucci/code/ml_experiments/work/8e8fc054b88b479ca408ce5f56e64860",
         "0.0",
         "None",
         "False",
         "2",
         "None",
         "None",
         "0.0",
         "0.1",
         "kindly-newt-176",
         "False"
        ],
        [
         "1",
         "f4679f0956a64c558879c360836413ff",
         "1",
         "FINISHED",
         "/home/belucci/code/ml_experiments/mlruns/1/f4679f0956a64c558879c360836413ff/artifacts",
         "2025-06-26 19:08:52.589000+00:00",
         "2025-06-26 19:08:52.891000+00:00",
         "330.304",
         "330.304",
         "0.2284525750001194",
         "0.9333333333333333",
         "330.304",
         "0.1",
         "log_loss",
         "0.0",
         "friedman_mse",
         "0.0001",
         "43",
         "1",
         "0",
         "None",
         "None",
         "1.0",
         "None",
         "3",
         "83e1c11371cc88d32a3f628247189140015a0b90",
         "None",
         "100",
         "None",
         "False",
         "/home/belucci/code/ml_experiments/work/f4679f0956a64c558879c360836413ff",
         "0.0",
         "None",
         "False",
         "2",
         "None",
         "None",
         "0.0",
         "0.1",
         "nebulous-duck-591",
         "False"
        ],
        [
         "2",
         "5413c635c3dd4657a3e89a34123b215f",
         "1",
         "FINISHED",
         "/home/belucci/code/ml_experiments/mlruns/1/5413c635c3dd4657a3e89a34123b215f/artifacts",
         "2025-06-26 19:08:52.017000+00:00",
         "2025-06-26 19:08:52.520000+00:00",
         "329.664",
         "330.176",
         "0.4372436289995676",
         "1.0",
         "330.176",
         "0.1",
         "log_loss",
         "0.0",
         "friedman_mse",
         "0.0001",
         "42",
         "1",
         "0",
         "None",
         "None",
         "1.0",
         "None",
         "3",
         "83e1c11371cc88d32a3f628247189140015a0b90",
         "None",
         "200",
         "None",
         "False",
         "/home/belucci/code/ml_experiments/work/5413c635c3dd4657a3e89a34123b215f",
         "0.0",
         "None",
         "False",
         "2",
         "None",
         "None",
         "0.0",
         "0.1",
         "agreeable-crow-466",
         "False"
        ],
        [
         "3",
         "22e01906466448718ad49ee6f54f2962",
         "1",
         "FINISHED",
         "/home/belucci/code/ml_experiments/mlruns/1/22e01906466448718ad49ee6f54f2962/artifacts",
         "2025-06-26 19:08:51.621000+00:00",
         "2025-06-26 19:08:51.940000+00:00",
         "329.28",
         "329.408",
         "0.22787985600007232",
         "1.0",
         "329.408",
         "0.1",
         "log_loss",
         "0.0",
         "friedman_mse",
         "0.0001",
         "42",
         "1",
         "0",
         "None",
         "None",
         "1.0",
         "None",
         "3",
         "83e1c11371cc88d32a3f628247189140015a0b90",
         "None",
         "100",
         "None",
         "False",
         "/home/belucci/code/ml_experiments/work/22e01906466448718ad49ee6f54f2962",
         "0.0",
         "None",
         "False",
         "2",
         "None",
         "None",
         "0.0",
         "0.1",
         "resilient-wasp-101",
         "False"
        ]
       ],
       "shape": {
        "columns": 40,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>status</th>\n",
       "      <th>artifact_uri</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>metrics.max_memory_used_before_fit</th>\n",
       "      <th>metrics.max_memory_used_after_fit</th>\n",
       "      <th>metrics.total_elapsed_time</th>\n",
       "      <th>metrics.accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>params.min_impurity_decrease</th>\n",
       "      <th>params.log_path</th>\n",
       "      <th>params.cuda_available</th>\n",
       "      <th>params.min_samples_split</th>\n",
       "      <th>params.init</th>\n",
       "      <th>params.n_iter_no_change</th>\n",
       "      <th>params.ccp_alpha</th>\n",
       "      <th>params.learning_rate</th>\n",
       "      <th>tags.mlflow.runName</th>\n",
       "      <th>tags.raised_exception</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8e8fc054b88b479ca408ce5f56e64860</td>\n",
       "      <td>1</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>/home/belucci/code/ml_experiments/mlruns/1/8e8...</td>\n",
       "      <td>2025-06-26 19:08:52.997000+00:00</td>\n",
       "      <td>2025-06-26 19:08:53.465000+00:00</td>\n",
       "      <td>330.304</td>\n",
       "      <td>330.304</td>\n",
       "      <td>0.405804</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>kindly-newt-176</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f4679f0956a64c558879c360836413ff</td>\n",
       "      <td>1</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>/home/belucci/code/ml_experiments/mlruns/1/f46...</td>\n",
       "      <td>2025-06-26 19:08:52.589000+00:00</td>\n",
       "      <td>2025-06-26 19:08:52.891000+00:00</td>\n",
       "      <td>330.304</td>\n",
       "      <td>330.304</td>\n",
       "      <td>0.228453</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>nebulous-duck-591</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5413c635c3dd4657a3e89a34123b215f</td>\n",
       "      <td>1</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>/home/belucci/code/ml_experiments/mlruns/1/541...</td>\n",
       "      <td>2025-06-26 19:08:52.017000+00:00</td>\n",
       "      <td>2025-06-26 19:08:52.520000+00:00</td>\n",
       "      <td>329.664</td>\n",
       "      <td>330.176</td>\n",
       "      <td>0.437244</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>agreeable-crow-466</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22e01906466448718ad49ee6f54f2962</td>\n",
       "      <td>1</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>/home/belucci/code/ml_experiments/mlruns/1/22e...</td>\n",
       "      <td>2025-06-26 19:08:51.621000+00:00</td>\n",
       "      <td>2025-06-26 19:08:51.940000+00:00</td>\n",
       "      <td>329.280</td>\n",
       "      <td>329.408</td>\n",
       "      <td>0.227880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>resilient-wasp-101</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id experiment_id    status  \\\n",
       "0  8e8fc054b88b479ca408ce5f56e64860             1  FINISHED   \n",
       "1  f4679f0956a64c558879c360836413ff             1  FINISHED   \n",
       "2  5413c635c3dd4657a3e89a34123b215f             1  FINISHED   \n",
       "3  22e01906466448718ad49ee6f54f2962             1  FINISHED   \n",
       "\n",
       "                                        artifact_uri  \\\n",
       "0  /home/belucci/code/ml_experiments/mlruns/1/8e8...   \n",
       "1  /home/belucci/code/ml_experiments/mlruns/1/f46...   \n",
       "2  /home/belucci/code/ml_experiments/mlruns/1/541...   \n",
       "3  /home/belucci/code/ml_experiments/mlruns/1/22e...   \n",
       "\n",
       "                        start_time                         end_time  \\\n",
       "0 2025-06-26 19:08:52.997000+00:00 2025-06-26 19:08:53.465000+00:00   \n",
       "1 2025-06-26 19:08:52.589000+00:00 2025-06-26 19:08:52.891000+00:00   \n",
       "2 2025-06-26 19:08:52.017000+00:00 2025-06-26 19:08:52.520000+00:00   \n",
       "3 2025-06-26 19:08:51.621000+00:00 2025-06-26 19:08:51.940000+00:00   \n",
       "\n",
       "   metrics.max_memory_used_before_fit  metrics.max_memory_used_after_fit  \\\n",
       "0                             330.304                            330.304   \n",
       "1                             330.304                            330.304   \n",
       "2                             329.664                            330.176   \n",
       "3                             329.280                            329.408   \n",
       "\n",
       "   metrics.total_elapsed_time  metrics.accuracy  ...  \\\n",
       "0                    0.405804          0.933333  ...   \n",
       "1                    0.228453          0.933333  ...   \n",
       "2                    0.437244          1.000000  ...   \n",
       "3                    0.227880          1.000000  ...   \n",
       "\n",
       "   params.min_impurity_decrease params.log_path params.cuda_available  \\\n",
       "0                           0.0            None                 False   \n",
       "1                           0.0            None                 False   \n",
       "2                           0.0            None                 False   \n",
       "3                           0.0            None                 False   \n",
       "\n",
       "  params.min_samples_split params.init params.n_iter_no_change  \\\n",
       "0                        2        None                    None   \n",
       "1                        2        None                    None   \n",
       "2                        2        None                    None   \n",
       "3                        2        None                    None   \n",
       "\n",
       "  params.ccp_alpha params.learning_rate tags.mlflow.runName  \\\n",
       "0              0.0                  0.1     kindly-newt-176   \n",
       "1              0.0                  0.1   nebulous-duck-591   \n",
       "2              0.0                  0.1  agreeable-crow-466   \n",
       "3              0.0                  0.1  resilient-wasp-101   \n",
       "\n",
       "  tags.raised_exception  \n",
       "0                 False  \n",
       "1                 False  \n",
       "2                 False  \n",
       "3                 False  \n",
       "\n",
       "[4 rows x 40 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cohirf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
